\documentclass{llncs}

\usepackage{url,amsmath,amssymb}
\usepackage{color}

% Dissemination Plans and Important Dates:

% - Your tutorial shall be acompanied by a paper,
% which will be published as a chapter of a book
% in the "Logic and Foundations of Mathematics" series
% by College Publications.

% - Please send us a good, though not necessarily final,
% version of your paper ** BEFORE 1st OF JUNE **.
% This will give us (and College Publications) sufficient time
% to produce printed copies of a preliminary version of the book,
% to be distributed to registered participants.

% - Afterwards there will be plenty of time to improve
% the paper/chapter and incorporate feedback gained during the event.


% General remarks:

% - The target audience (for both the tutorials and
% the accompanying papers) consists of Ph.D. students,
% young post-docs and researchers from other logic-related communities.

% - Avoid obscurity and clarify concepts that might be
% unknown to people from other communities.

% - Strive for a self-contained paper, but be concise and
% cite papers where readers may find more information.

% - Do not hesitate to build bridges between your domain and
% other proof-related communities if you have some ideas to do so.
% These bridges should lead to interesting discussions during the workshop.

% - You are encouraged to compare what is done in your community
% with what is done in other communities.
% Try to understand and explain why your community does things differently.
% This could lead to interesting discussions too.

% - This template aims at ensuring a
% reasonably uniform style for all speakers.
% Nevertheless, feel free to deviate from the template if you need.
% We are aware that not all questions are applicable to all speakers.


% We hope the questions here will guide you
% in the production of your tutorial.

% If anything is unclear, if you have any questions, contact us!

% Thank you!

\newcommand{\Note}[1]{\textcolor{blue}{[#1]}}

\title{ Proofs in Satisfiability Modulo Theories }
% Please select a general title that reflects
% the community you are going to represent in the event.

\author{
  Clark Barrett \inst{1}
  \and
  Leonardo de Moura \inst{2}
  \and
  Pascal Fontaine \inst{3}
}

\authorrunning{C.\~Barrett \and L.\~de Moura \and P.\~Fontaine}

\institute{
  New York University\\
  \email{barrett@cs.nyu.edu}
  \and
  Microsoft Research \\
  \email{leonardo@microsoft.com}
  \and
  University of Lorraine and INRIA\\
  \email{pascal.fontaine@inria.fr}
}

\begin{document}

\maketitle

\section{Introduction}

Satisfiability Modulo Theories (SMT) solvers\footnote{We refer
  to~\cite{Barrett14} for a survey on SMT.} check the satisfiability of (mostly
first-order) formulas written in a language containing interpreted predicates
and functions.  These interpreted symbols are defined by a first-order theory
(e.g.\ equality, array operators {\tt read} and {\tt write},\dots) or by a
structure (e.g.\ the integer numbers equipped with constants, addition,
equality, and inequalities).  Theories usually implemented within SMT solvers
include the empty theory (a.k.a.\ the theory of uninterpreted symbols with
equality), linear arithmetic on integers and/or reals, non-linear arithmetic on
reals, bit-vectors and the theory of arrays.  A very small example of input
formula for an SMT solver is
\begin{equation}\label{eq:example}
a \leq b \wedge b \leq a + x \wedge x = 0 \wedge
 \big[ f(a) \neq f(b) \vee (q(a) \wedge \neg q(b + x)) \big].
\end{equation}
The above formula uses equality, linear arithmetic and uninterpreted symbols
($q$ and $f$), within some Boolean combination.  The input language of SMT
solvers is standardized in the SMT-LIB format, currently in its version
2.0~\cite{Barrett15}.  Figure~\ref{fig:smtlib} gives a translation of our example formula
in this format.  The format currently does not provide any guideline for proof
output.

\begin{figure}
{\footnotesize
\begin{verbatim}
(set-logic QF_UFLRA)
(set-info :source | Example formula in SMT-LIB 2.0 |)
(set-info :smt-lib-version 2.0)
(declare-fun f (Real) Real)
(declare-fun q (Real) Bool)
(declare-fun a () Real)
(declare-fun b () Real)
(declare-fun x () Real)
(assert (and (<= a b) (<= b (+ a x)) (= x 0)
             (or (not (= (f a) (f b))) (and (q a) (not (q (+ b x)))))))
(check-sat)
(exit)
\end{verbatim}
}
\caption{\label{fig:smtlib} An formula, written in SMT-LIB 2.0}
\end{figure}

Whereas SMT solvers were designed originally as decision procedures for
decidable quantifier-free fragments, some SMT solvers nowadays tackle
quantifiers, are decision procedures for some decidable quantified fragments
(see e.g.~\cite{Ge1,Ge2}), and refutational completeness for first-order logic
(with equality but without further interpreted symbols) is an explicit goal.
Also, some SMT solvers now deal with theories that are undecidable even in the
quantifier-free case, for instance non-linear arithmetic on integers~\cite{Borralleras1}.

In some aspects, and also in their implementation, SMT solvers can be seen as
extensions of propositional satisfiability (SAT) solvers to more expressive
languages.  They lift the efficiency of SAT solvers to richer logics:
state-of-the-art SMT solvers are able to deal with very large formulas,
containing thousands of atoms.  Very schematically, an SMT solver abstracts its
input to propositional logic by replacing every atom with a fresh proposition,
e.g., for the above example,
\begin{displaymath}
p_{a \leq b} \wedge p_{b \leq a + x} \wedge p_{x = 0} \wedge
 \big[ \neg p_{f(a) = f(b)} \vee (p_{q(a)} \wedge \neg p_{q(b + x)}) \big].
\end{displaymath}
The underlying SAT solver is used to provide Boolean models for this
abstraction, e.g.\
\begin{displaymath}
\{ p_{a \leq b}, p_{b \leq a + x}, p_{x = 0}, \neg p_{f(a) = f(b)} \}
\end{displaymath}
and the theory reasoner repeatedly refutes these models and refines the Boolean
abstraction by adding new clauses (in this case $\neg p_{a \leq b} \vee \neg
p_{b \leq a + x} \vee \neg p_{x = 0} \vee p_{f(a) = f(b)}$) until either the
theory reasoner agrees with the model found by the SAT solver, or the
propositional abstraction is refined to an unsatisfiable formula.  As a
consequence, propositional reasoning and theory reasoning are quite well
distinguished.  Naturally, the interaction between the theory reasoner and the
SAT reasoning is in practice much more subtle than the above naive description,
but even when advanced techniques (e.g.\ eager decision procedures\marginpar{I
  am always confused about the best term to use here, online, eager\dots Please
  correct me} and theory propagation, see again~\cite{Barrett14}) are used,
propositional and theory reasoning are not very strongly mixed.  SMT proofs will
also feature an interleaving of SAT proofs and theory reasoning proofs.

% PF this should be improved
The theory reasoner may be a decision procedure for one theory, e.g.\ congruence
closure~\cite{Nelson2,Nieuwenhuis6} for uninterpreted symbols or a simplex-based
procedure~\cite{Dutertre1} for linear arithmetics, but it is most of the time a
combination of decision procedures.  Combination
frameworks~\cite{Nelson3,Tinelli1} build decision procedures for sets of
literals mixing interpreted symbols from several decidable languages (like the
aforementioned linear arithmetic and uninterpreted symbols) into one decision
procedure for the union of languages.  Combining decision procedures is possible
if the theories in the combination fulfill some properties.  For instance,
theories used in SMT solvers are often \emph{stably-infinite}\footnote{A theory
  is stably-infinite if every satisfiable set of literals in the theory has an
  infinite model.} and disjoint; this is notably the case for linear arithmetic
on integers and reals, and for uninterpreted symbols.  Combining theories often
either involve guessing which shared terms are equal and which are not, or,
equivalently, communicating disjunctions of equalities between decision
procedures.  Again, proofs for a combination of theories will be built from
proofs related to the theories in the combinations; the component proofs will
simply be combined using Boolean reasoning rules.

Quantifier reasoning in SMT is still mostly done through
instantiation~\cite{Moura9}.  Proofs involving quantifier reasoning are thus
just ground proofs augmented with some instantiation steps.  Skolemization is
however not trivial.  Giving a detailed proof of clausification and rewriting of
the ground instances is also not an easy task.



\Note{Pascal}
% Briefly introduce your kind of proof production tool
% (e.g. Sat-solvers, SMT-solvers, First-order ATPs,
% Higher-order ATPs, Proof Assistants, ...).
% Try to give an overview encompasing all your community.
% If possible, do not to restrict yourself only to the tool(s) you develop.
Overview of proofs in SMT.  Proofs are basically resolution plus theory
lemmas.  Mention that one challenge is to keep enough information to produce
proofs without being too slow.

\Note{Clark}
% What are the tools that pioneered proof production in your area?
% What are the tools that currently produce proofs?
% How widespread is the feature of proof production
% among tools in your area?
% How was the historical evolution of the
% proof production feature in your area?
% If the tools in your area cannot produce proofs easily, explain why,
% and describe the current trends to alleviate this problem.
The Cooperating Validity Checker (CVC)~\cite{SBD02} was the first SMT solver to
tackle the problem of proof-production.  CVC was built by Aaron Stump and Clark
Barrett, advised by David Dill, at Stanford University.  CVC was designed to
improve upon and replace the Stanford Validity Checker (SVC)~\cite{BDL96} for
use in the group's verification applications and also to serve as a research
platform for studying SMT ideas and algorithms.    CVC
uses a proof format based on the Edinburgh Logical Framework (LF)~\cite{HHP93}
and its proofs can be checked using the flea proof-checker~\cite{SBD02b,SD02}, which was
developed concurrently with CVC.

The motivation for producing proofs was primarliy that it would provide a means
of independently certifying a correct result,
so that users would not have to rely on the correctness of a large and
frequently-changing code base.  Another motivation was the hope that
proof-production could aid in finding and correcting nasty bugs in CVC.
In retrospect, however, the most important and lasting contribution of CVC's
proof infrastructure was that it enabled an efficient integration of a SAT
solver for Boolean reasoning.  Initial attempts to use a SAT solver within
CVC suffered from poor performance because the theory-reasoning part of CVC
was being used as a black box, simply flagging a particular branch of the SAT
search as unsatisfiable.  Without additional information (i.e. a conflict
clause specifying a small reason for the unsatisfiability), the SAT solver could
not benefit from clause learning or non-chronlogical backjumping and frequently
failed to terminate, even on relatively easy problems.  During a conversation
with Cormaq Flanagan, the idea of using the proof infrastructure to compute
conflict clauses emerged, and this was the key to finally making the
integration with SAT efficient (see~\cite{BDS02-CAV02} for more details).  The
technique was implemented in CVC, as well as in Flanagan's solver called
Verifun~\cite{FJO+03} and this laid the groundwork for the so-called DPLL(T)
architecture~\cite{NieOT-JACM-06} used in nearly every modern SMT solver.

The next important development in proof-producing SMT solvers was the
early exploration of using proofs to communicate with skeptical proof
assistants.  The first work in this area~\cite{MBG06} was a translator designed
to import proofs from CVC Lite~\cite{BB04} (the successor to CVC) into HOL
Lite~\cite{H96}, a proof assistant for higher-order logic with a small trusted
core set of rules.  The goals of this work were two-fold: to provide access to
efficient decision procedures within HOL Lite and to enable the use of HOL Lite
as a proof-checker for CVC Lite.  Shortly thereafter~\cite{FMM+06,HCF+07}, a similar effort was
made to integrate the haRVey SMT solver~\cite{DR03} with the Isabelle/HOL prove
assistant~\cite{NPW02}. These early efforts demonstrated the feasibility of such
integrations.

In 2008, an effort was made to leverage this work to certify that the
benchmarks in the SMT-LIB library were correctly labeled (benchmarks are
labeled with a \emph{status} that can be ``sat'', ``unsat'', or ``unknown'',
indicating the expected result when solving the benchmark).  The certification
was done using CVC3~\cite{BT07} (the successor to CVC Lite) and
HOL Lite~\cite{GB08}.  Many of the benchmarks in the library were certified and
additionally, a bug in the library was found as two benchmarks that had been
labeled satisfiable were certified as unsatisfiable.
The same work reports briefly on an anecdote that further validates the value
of proof-production.  A latent bug in CVC3 was revealed during the 2007
SMT-COMP competition.  Using HOL Light as a proof-checker, the cause of the bug
was quickly detected as a faulty proof rule.  The bug in the proof rule had
persisted for years and would have been very difficult to detect without the
aid of the proof-checker.


%% Mention Fx7 - ``Rocket fast proof checking'' paper (TACAS 2008)
%% Proofs and Refutations (Z3) (IWIL 2008)
%% Towards an SMT Proof format SMT 2008, LFML 2008, SMT 2009
%% veriT 2009
%% PxTP 2011

%% preliminary report


%% History of proofs in SMT.  CVC tools, Z3, veriT
%% MathSAT has support for proofs, but unclear what the format is (brief mention
%% in MathSAT5 paper)

% Is there an open-source and minimalistic
% *proof-producing* version of your kind of tool that would be
% particularly suitable for beginners to look at and modify?
I fear CVC4 is too large to be good for beginners - how about veriT?

PF: veriT is much smaller than CVC4, but not cleaner.  One can say:

Unlike SAT solvers, SMT solvers are usually large pieces of software: besides
propositional reasoning engines, they include decision procedures that can
themselves be quite complex.  Furthermore, the code of the components (i.e.\ the
various decision procedures and the propositional reasoner) can be intricately
mixed together.  Implementing a new SMT solver from scratch, or even getting
into the code of an existing SMT solver, is a tedious task.  The OpenSMT
solver~\cite{} is maybe the one that includes the best in its philosophy a less
stiff learning curve for new developers.

\section{Proof Systems and Proof Consumption}

\Note{Pascal}
What are the common proof techniques across SMT?  Mention resolution,
equality/congruence reasoning.  Otherwise, theory-specific reasoning varies a lot.

% Please list the (most common) proof systems
% (e.g. resolution, superposition, tableaux,
% sequent calculus, natural deduction, ...)
% underlying state-of-the-art tools of your kind.

% Please show the inference rules of
% (some of) these proof systems explicitly.
% Use, for example, proof.sty or bussproofs.sty.

% Why are these proof systems particularly useful for
% your automated deduction tools?
% Which features make them suitable?
% What is not so convenient in them?

% What are the trends w.r.t. proof systems for your kind of tool?

%\section{Proof Consumption}
Discuss how SMT solvers depend on reolution proofs from SAT.

% Does your kind of tool consume proofs from another kind of tool?
% (e.g. SMT-solvers using (proofs from) sat-solvers;
% higher-order ATPs and proof assistants using (proofs from)
% first-order ATPs; ...)

% If so, is there anything that could be improved in the proofs
% that are generated by this other kind of tool?

% If your tool consumes proofs from other tools,
% is it only a proof-checker or is
% it a wider tool also used to build proofs by its own?
% If it is a wider tool, do you also provide a lighter version of
% your tool that is dedicated to proof-checking?
% If not, would it be desirable?

% What are the trends?


\section{Proof Search}

\Note{Clark}
SMT solvers typically include a module for preprocessing formulas to simplify
them before running the main algorithm to search for a satisfying assignment.
This module may perform anything from simple rewrites (such as rewriting $x=y$
to $y=x$) to complex global simplifications that significantly change the
structure of the formula.

Preprocessing poses a challenge for proof-production.  Each transformation done
by the preprocessor must be reflected in the produced proof.

How do the proof search techniques in SMT affect proof production?  For
example, rewriting, CNF conversion, preprocessing are challenging for proofs.
Some processing is typically disabled when producing proofs.

% Which algorithms are used to search for a proof/refutation?
% Is the procedure able to find (counter-)models as well?

% Which criteria (e.g. speed, sizes (or other measures) of proofs/models)
% are used to evaluate whether a procedure is better than another?

% What are the "bottlenecks" that prevent current procedures
% from solving more problems?

% Is there any mismatch between the abstract proof systems and
% the implemented proof search procedures?
% If so, how big is the gap between proof theory
% and automated deduction in your field?
% Would it be possible/desirable to develop proof systems
% that are closer to the actual implementations?

% Are there any particular decision procedures or
% proof search procedures that are not well-covered by proof theory yet?

% Do the proof search procedures guarantee that an optimal proof
% (for some sense of "optimal") will be found, if a proof exists?

% Are there proof search optimization techniques
% (e.g. resolution refinements, subsumption,
% in-processing) that succesfully improve theorem proving efficiency,
% but may be harmful for the generation of "good" (e.g. short, detailed, easy to check, ...) proofs?
% Which techniques are harmful? Which are harmless?

% If the generated proofs are not optimal,
% what kinds of redundancies may they contain?
% Are there methods to improve the proofs in a post-processing phase?
% Would it be possible/profitable to modify the existing
% proof search procedures so that they generate better proofs,
% that do not need to be post-processed afterwards?

% If the generated proofs are optimal but depend on the
% kind of proof-checker that is used to verify the produced proofs,
% explicit the dependency you rely on to generate optimal proofs.

% What are the trends w.r.t. proof search methods for your kind of tool?

\section{Introduction to Proof Implementations for SMT}

\Note{Clark}
There is no standard format for SMT.  There has been some discussion and even
some proposals.  Mention various proposals.  Below, we will discuss four
implementations of proofs in SMT.  The approaches are different enough to
warrant separate treatment.

\section{The CVC Family of SMT Solvers}
\Note{Clark}
\subsection{Proof Formats}
\subsection{Proof Production}
\subsection{Proof Applications}

\section{The veriT SMT Solver}

The veriT SMT solver is developed jointly at Loria, Nancy (France) and UFRN,
Natal (Brazil).  It is open-source, under the permissive BSD licence.  veriT is
first a testing plate-form for techniques developed around SMT, but it is
sufficienctly stable to be used by third parties.  Proofs in veriT are mainly
resolution proofs interleaved with theory reasoning lemmas.

\subsection{Proof Formats}

The proof trace language of veriT is inspired from the SMT-LIB 2.0 standard.  A
sample proof for our running example~ref{eq:example} is given in
Figure~\ref{fig:proofverit}.  The language is quite coarse grained and rather
falls into the ``proof trace'' category rather than full detailed proof.  It
provides however a full account of the resolution proof, and equality reasoning
is broken down into applications of the congruence and transitivity instances of
the axiom schemas for equality.  Symmetry of equality is silently used
uniformly.  Special proof rules are assigned to theory lemmas (from arithmetic),
but veriT does not break down arithmetic reasoning to instances of
e.g., Presburger axioms.  The example here does not feature quantifier
reasoning; proofs with quantifiers use quantifier instantiation rules.

Skolemization, 

\begin{figure}
{\scriptsize
\begin{verbatim}
(set .c1 (input :conclusion ((and (<= a b) (<= b (+ a x)) (= x 0)
                               (or (not (= (f b) (f a))) (and (q a) (not (q (+ b x)))))))))
(set .c2 (and :clauses (.c1) :conclusion ((<= a b))))
(set .c3 (and :clauses (.c1) :conclusion ((<= b (+ a x)))))
(set .c4 (and :clauses (.c1) :conclusion ((= x 0))))
(set .c5 (and :clauses (.c1) :conclusion
           ((or (not (= (f b) (f a))) (and (q a) (not (q (+ b x))))))))
(set .c6 (and_pos :conclusion ((not (and (q a) (not (q (+ b x))))) (q a))))
(set .c7 (and_pos :conclusion ((not (and (q a) (not (q (+ b x))))) (not (q (+ b x))))))
(set .c8 (or :clauses (.c5) :conclusion
           ((not (= (f b) (f a))) (and (q a) (not (q (+ b x)))))))
(set .c9 (eq_congruent :conclusion ((not (= a b)) (= (f b) (f a)))))
(set .c10 (la_disequality :conclusion ((or (= a b) (not (<= a b)) (not (<= b a))))))
(set .c11 (or :clauses (.c10) :conclusion ((= a b) (not (<= a b)) (not (<= b a)))))
(set .c12 (resolution :clauses (.c11 .c2) :conclusion ((= a b) (not (<= b a)))))
(set .c13 (la_generic :conclusion ((not (<= b (+ a x))) (<= b a) (not (= x 0)))))
(set .c14 (resolution :clauses (.c13 .c3 .c4) :conclusion ((<= b a))))
(set .c15 (resolution :clauses (.c12 .c14) :conclusion ((= a b))))
(set .c16 (resolution :clauses (.c9 .c15) :conclusion ((= (f b) (f a)))))
(set .c17 (resolution :clauses (.c8 .c16) :conclusion ((and (q a) (not (q (+ b x)))))))
(set .c18 (resolution :clauses (.c6 .c17) :conclusion ((q a))))
(set .c19 (resolution :clauses (.c7 .c17) :conclusion ((not (q (+ b x))))))
(set .c20 (eq_congruent_pred :conclusion ((not (= a (+ b x))) (not (q a)) (q (+ b x)))))
(set .c21 (resolution :clauses (.c20 .c18 .c19) :conclusion ((not (= a (+ b x))))))
(set .c22 (la_disequality :conclusion ((or (= a (+ b x)) (not (<= a (+ b x))) (not (<= (+ b x) a))))))
(set .c23 (or :clauses (.c22) :conclusion ((= a (+ b x)) (not (<= a (+ b x))) (not (<= (+ b x) a)))))
(set .c24 (resolution :clauses (.c23 .c21) :conclusion ((not (<= a (+ b x))) (not (<= (+ b x) a)))))
(set .c25 (eq_congruent_pred :conclusion
            ((not (= a b)) (not (= (+ a x) (+ b x))) (<= a (+ b x)) (not (<= b (+ a x))))))
(set .c26 (eq_congruent :conclusion ((not (= a b)) (not (= x x)) (= (+ a x) (+ b x)))))
(set .c27 (eq_reflexive :conclusion ((= x x))))
(set .c28 (resolution :clauses (.c26 .c27) :conclusion ((not (= a b)) (= (+ a x) (+ b x)))))
(set .c29 (resolution :clauses (.c25 .c28) :conclusion ((not (= a b)) (<= a (+ b x)) (not (<= b (+ a x))))))
(set .c30 (resolution :clauses (.c29 .c3 .c15) :conclusion ((<= a (+ b x)))))
(set .c31 (resolution :clauses (.c24 .c30) :conclusion ((not (<= (+ b x) a)))))
(set .c32 (la_generic :conclusion ((<= (+ b x) a) (not (= a b)) (not (= x 0)))))
(set .c33 (resolution :clauses (.c32 .c4 .c15 .c31) :conclusion ()))
\end{verbatim}
}
\caption{\label{fig:proofverit} The proof output by veriT for example Formula \ref{eq:example}.  The output has been slightly edited to cut and indent long lines.}
\end{figure}

In the future, the proof format of veriT will be further improved to even better
stick to the SMT-LIB standard.  In particular, when using shared terms, veriT
uses a notation to label repeating formulas which is inspired from early CVC custom input language, but which does not fit well with .

\subsection{Proof Production}



\subsection{Proof Applications}

PF this needs improvement


Users targeted by our format are people who would like to replay those proofs into proof assistants, people working on interpolation (veriT does not provide a service for interpolation), and people wanting unsat cores (proofs are here overkill, but proofs are a way to get unsat cores without getting into the solver and design special techniques).

Georg Hofferek has used our proofs for multiple interpolant computation in some synthesis problems (TODO more details/citation later).  In the Rodin plugin to SMT, veriT's proofs are used as a mean to quickly extract a core.  Proofs from veriT are used in Coq-SMT (TODO should check) for proof reconstruction of SMT proofs.

\section{The Z3 SMT Solver}

Z3 is a Satisfiability Modulo Theories (SMT) solver developed at
Microsoft Research.  Z3 source code is available online, and it is
freely for non-commercial purposes.  Z3 is used in various software
analysis and test-case generation projects at Microsoft Research and
elsewhere.  Proof generation is based on two simple ideas: (1) a
notion of implicit quotation to avoid introducing auxiliary variables,
it simplifies the creation of proof objects considerably; (2) natural
deduction style proofs to facilitate modular proof re-construction.

\subsection{Proof Format and Production}

In Z3, proof objects are represented as terms. So a proof-tree is just a term
where each inference rule is represented by a function symbol.
For example, consider the proof-rule $mp(p, q, \varphi)$, where $p$ is a proof for
$\psi \rightarrow \varphi$ and $q$ is a proof for $\psi$. Each proof-rule has
\emph{consequent}, the consequent of $mp(p, q, \varphi)$ is $\varphi$.

A basic underlying principle for composing and building proofs in Z3 has been to support a modular
architecture that works well with theory solvers that receive literal assignments from other solvers and
produce contradictions or new literal assignments. The theory solvers should be able to produce independent
and opaque explanations for their decisions.
Conceptually, each solver acts upon a set of hypotheses and produce a consequent. The basic proof-rules
that support such an architecture can be summarized as: \emph{hypothesis} , that allow introducing an
assumption, \emph{lemma}, that eliminates hypotheses, and \emph{unit resolution} that handles basic propagation.
We say that a proof-term is \emph{closed} when every path that ends with a hypothesis contains an application
of rule lemma. If a proof-term is not closed, it is open.

The main propositional inference engine in Z3 is based on a DPLL(T) architecture.
The DPLL(T) proof search method lends itself naturally to producing resolution style proofs.
Systems, such as zChaff, and a version of MiniSAT, produce proof logs based on logging the
unit propagation steps as well as the conflict resolution steps. The resulting log suffices to produce a
propositional resolution proof.

The approach taken in Z3 bypasses logging, and instead builds proof
objects during conflict resolution.  With each clause we attach a
proof. Clauses that were produced as part of the input have proofs
that were produced from the previous steps. This approach does not
require logging resolution steps for every unit-propagation, but
delays the analysis of which unit propagation steps are useful until
conflict resolution. The approach also does not produce a resolution
proof directly. It produces a natural deduction style proof with
hypotheses.

The theory of equality can be captured by axioms for reflexivity,
symmetry, transitivity, and substitutivity of equality. In Z3,
these axioms are inference rules, and these inference rules apply
for any binary relation that is reflexive,
symmetric, transitive, and/or reflexive-monotone.

n the DPLL(T) architecture, decision procedures for a theory $T$
identify sets of asserted $T$-inconsistent literals. Dually, the
disjunction of the negated literals are $T$-tautologies. Consequently,
proof terms created by theories can be summarized using a single form,
here called \emph{theory lemmas}. Some theory lemmas are annotated
with hints to help proof checkers and reconstruction. For example, the
theory of linear arithmetic produces theory lemmas based on Farka's
lemma. For example, suppose $p$ is a proof for $x > 0$, and $q$ is a
proof for $2x + 1 < 0$, then $\mbox{\emph{farkas}}(1, p, -1/2, q, \neg(x > 0) \vee \neg(2x + 1 < 0))$
is a theory lemma where the coefficients $1$ and $-1/2$ are hints.

The Z3 simplifier applies standard simplification rules for the
supported theories. For example, terms using the arithmetical operations,
both for integer, real, and bit-vector arithmetic, are normalized into sums of monomials.
A single proof rule called \emph{rewrite} is used to record the simplification steps.
For example, $\mbox{\emph{rewrite}}(x + x = 2 x)$ is a proof for $x + x = 2x$.

Notice that Z3 does not axiomatize the legal rewrites.
Instead, to check the rewrite steps, one must rely on a
proof checker to be able to apply similar inferences for the set of built-in theories.

\subsection{Proof Applications}

The two main applications for Z3 proof certificates are: proof
reconstruction in interactive proof assistant such as
Isabelle~\cite{IsabelleZ3}; an interpolation generation~\cite{iZ3}.

In Isabelle/HOL, Z3 proofs are reconstructed in a completely different
system based on a secure proof kernel. Proof reconstruction is a quite
involved process, because proof rules such as \emph{theory lemmas} require
several steps of reasoning in Isabelle/HOL.

The interpolation prover iZ3~\cite{iZ3} is implemented on top of Z3.  It uses Z3
proof as guide for construction of a proof by a secondary, less
efficient, interpolating prover. It translates Z3 proofs into
a proof calculus that does admit feasible interpolation, with
``gaps'', or lemmas, that must be discharged by the secondary prover.


\section{The Lean Prover}
\Note{Leonardo}
\subsection{Proof Formats}
\subsection{Proof Production}
\subsection{Proof Applications}

%\section{Proof Formats}

% Briefly describe the actual text formats used to output proofs.

% Are there standard formats in your community? If not, why not?

% If possible and if not too large, please copy-paste the
% grammar of the proof format(s) here.

% Please copy-paste a small but interesting example proof here.
% Try to select an example that shows (most of) the peculiarities
% of your proof format.
% Use a verbatim environment (like the listings package, for example).

% What are the guiding principles involved in the design of the format?
% Is it intended to be human-readable? easy to parse?
% easy/efficient to verify? as small as possible?
% In case of automated proofs, is it intended to recover
% intuition of the proofs?

% If a proof expressed in your proof format is intended
% to be checked by another tool, what is the distribution
% between the information that is stored in the
% proof and the information that has to be reconstructed by
% the tool verifying the proof.

% Is there any relation between the proof format and
% the format used for input problems?

% How fine- or coarse-grained are the proofs in this format?
% Are you and your community satisfied with this level of detail?
% Are there applications that might benefit from
% a greater level of detail?

% If you provide several proof formats,
% explain the kinds of users that are targeted by these formats.

% Are there generic parsers available for this format?
% In which programming languages?

% What are the trends?


%\section{Proof Production}

% What is the ``price'' (e.g. in terms of efficiency or memory overhead)
% paid to generate proofs? How much slower does the tool become?
% How much more memory does it consume?

% In case of automated proofs, how different is the proof-producing
% proof search algorithm from the proof search algorithm that simply
% answers "yes" or "no"?

% Is it usually possible to switch proof production
% on and off in your kind of tool?

% How is the code for proof production?
% Does it require substantial intervention in the usual architecture
% and data structures of a non-proof-producing tool of the same kind?
% Could you show some code snippets here, in order to
% illustrate proof production?
% If there is a significant gap between the proof system and
% the actual data structures used by the tool,
% could you illustrate (perhaps with a simple example)
% how a proof can be obtained from these data structures?

% Does your kind of tool keep the (partial) proof in memory during
% the search and writes it to a file only when the search finishes?
% Or does it write partial results (lemmas) eagerly to file?
% In this latter case, are there techniques to cope with
% excessive generation and writing of lemmas that may not be
% relevant to prove the theorem?

% What are the trends?


%\section{Proof Applications}

% Which application domains have used your kind of tool?
% Have there been any ground-breaking achievements?
% Among these application domains,
% which are particularly interested in the generated proofs?
% How do they use the proofs? Do they use proofs just for
% certifying the correctness of the provided answer?
% Or do they extract other kinds of information
% (e.g. unsat cores, interpolants, witnesses, programs, ...) from proofs?

% In the context of these applications, when should
% a proof P of a certain theorem be considered better than
% a proof Q of the same theorem?
% For example, in case of double negation transformations,
% why is it better to get intuitionistic proofs from classical proofs?

% What are the trends?


\section{Conclusions}

% Summarize the most important points of the previous sections.

Building a proof-producing SMT solver is mostly easy: the underlying SAT solver
mainly produces a resolution proof, and, as long as the theories in the
combination also produce proof, the combination can also be see as a resolution
proof.  There remains however many small and larger challenges related to SMT
proofs.  First, it is necessary to collect and store all the necessary
information to produce the final proof; this is mostly a technical problem, but,
if this is done in memory, this can be the bottleneck of the proof search.
Second, SMT often relies on many preprocessing techniques, some being necessary
for the soundness of tool, some being useful for efficiency.  The attitude
followed by most SMT developer is to provide some kind of high level proof of
for essential preprocessing.  Non-essential preprocessing is turned off, with an
important consequence on efficiency.  Finally may also be non-trivial to provide
good proofs for some preprocessing techniques, e.g.\ for Skolemization, or
symmetry breaking.

SMT solvers may use external tools as specialized reasoners for some theories.
Producing a proof in SMT may thus, in some cases, require proofs from those
external reasoners.

An important challenge for the SMT community is to provide a proof format which
is sufficiently flexible to accomodate all needs, sufficiently compact to be
practical, and sufficiently elegant (with is a very subjective quality) to be
accepted by most.  Some formats have been proposed~\cite{}, but none is
sufficiently mature to be accepted by the whole community.

% Thank you very much for your contribution!

\medskip
\emph{Acknowledgements}: Pascal Fontaine would like to thank David D\'{e}harbe,
who jointly designed veriT with him.


\bibliographystyle{plain}
\bibliography{SMTProofs}

\end{document}
